{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets(\"MNIST_data/\")\n",
    "trX, trY, teX, teY=mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAutoEncoder(object):\n",
    "    def __init__(self, m, n, eta=0.01):\n",
    "        #m : Number of neurons in input/ output layer\n",
    "        #n : number of neurons in hidden layer\n",
    "        \n",
    "        self._m=m\n",
    "        self._n=n\n",
    "        self.learning_rate = eta\n",
    "        \n",
    "        # Create the Computation Graph\n",
    "        \n",
    "        #weights= and biases\n",
    "        self._w1=tf.Variable(tf.random_normal(shape=(self._m, self._n)))\n",
    "        self._w2=tf.Variable(tf.random_normal(shape=(self._n, self._m)))\n",
    "        self._b1=tf.Variable(np.zeros(self._n).astype(np.float32))     #bias for hidden layer\n",
    "        self._b2=tf.Variable(np.zeros(self._m).astype(np.float32))     #bias for output layer\n",
    "        \n",
    "        #placeholder for inputs\n",
    "        self._X=tf.placeholder('float', [None, self._m])\n",
    "        \n",
    "        self.y=self.encoder(self._X)\n",
    "        self.r=self.decoder(self.y)\n",
    "        error=self._X - self.r\n",
    "        \n",
    "        self._loss=tf.reduce_mean(tf.pow(error, 2))\n",
    "        alpha=7.5e-5\n",
    "        kl_div_loss=tf.reduce_sum(self.kl_div(0.02, tf.reduce_mean(self.y,  0)))\n",
    "        loss=self._loss + alpha + kl_div_loss\n",
    "        self._opt=tf.train.AdamOptimizer(self.learning_rate).minimize()\n",
    "        \n",
    "        def encoder(self, x):\n",
    "            h=tf.matmul(x, self._w1) + self._b1\n",
    "            return tf.nn.sigmoid(h)\n",
    "        \n",
    "        \n",
    "        def decoder(self, x):\n",
    "            h = tf.matmul(x, self._W2) + self._b2\n",
    "            return tf.nn.sigmoid(h)\n",
    "        def set_session(self, session):\n",
    "            self.session= session\n",
    "            \n",
    "        def reduced_dimension(self, x):\n",
    "            h= self.encoder(x)\n",
    "            return self.session.run(h, feed_dict={self._X: x})\n",
    "        \n",
    "        def reconstruct(self, x):\n",
    "            h=self.encoder(x)\n",
    "            r=self.decoder(h)\n",
    "            return self.session.run(r, feed_dict={self._X: x})\n",
    "        \n",
    "        def kl_div(self, rho, rho_hat):\n",
    "            term2_num= tf.constant(1.) - rho\n",
    "            term2_den= tf.constant(1.) - rho_hat\n",
    "            kl=self.logfunc(rho, rho_hat) + self.logfunc(term2_num, term2_den)\n",
    "            return kl\n",
    "\n",
    "        def logfunc(self, x1, x2):\n",
    "            return tf.multiply(x1, tf.log(tf.div(x1, x2)))\n",
    "        \n",
    "        def fit(self, X, epochs = 10, batch_size=100):\n",
    "            N, D= X.shape\n",
    "            \n",
    "            num_batches= N//batch_size\n",
    "            \n",
    "            obj=[]\n",
    "            for i in range(epochs):\n",
    "                #X= shuffle(X)\n",
    "                \n",
    "                for j in range(num_batches):\n",
    "                    batch = X[j*batch_size : (j*batch_size + batch_size)]\n",
    "                    _, ob=self.session.run([self._opt, self._loss], feed_dict={self._X: batch})\n",
    "                    \n",
    "                    if j %100 ==0:\n",
    "                        print('training epoch {0} batch {2} cost {1}'. format(i, ob, j))\n",
    "                        obj.append(obj)\n",
    "                        return obj\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SparseAutoEncoder' object has no attribute 'encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6610757b5968>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msae\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mSparseAutoEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Initialise all variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2b9dd2a2a01d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, m, n, eta)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SparseAutoEncoder' object has no attribute 'encoder'"
     ]
    }
   ],
   "source": [
    "Xtrain= trX.astype(np.float32)\n",
    "Xtest= teX.astype(np.float32)\n",
    "_, m = Xtrain.shape\n",
    "\n",
    "sae= SparseAutoEncoder(m , 256)\n",
    "\n",
    "#Initialise all variables\n",
    "\n",
    "init= tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sae.set_session(sess)\n",
    "    err=sae.fit(Xtrain, epochs=10)\n",
    "    out=sae.reconstruct(Xtest[0:100])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'err' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-bca0ebbf0fde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reconstruction loss (MSE)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'err' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(err)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Reconstruction loss (MSE)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
